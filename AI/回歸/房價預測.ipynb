{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn \n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CRIM 住房所在城鎮的人均犯罪率\n",
    "- ZN 住房用地超過 25,000 平方尺的比例\n",
    "- INDUS 住房所在城鎮非零售商用土地的比例\n",
    "- CHAS 有關查理斯河的虛擬變數(如果住房位於河邊則為 1，否則為 0)\n",
    "- NOX 一氧化氮濃度\n",
    "- RM 每處住房的平均房間數\n",
    "- AGE 建於 1940 年之前的業主自住房比例\n",
    "- DIS 住房距離波士頓五大中心區域的加權距離\n",
    "- RAD 距離住房最近的公路入口編號\n",
    "- TAX 每 10,000 美元的全額財產稅金額\n",
    "- PTRATIO 住房所在城鎮的師生比例\n",
    "- B 1000(Bk-0.63)^2，其中 Bk 指代城鎮中黑人的比例\n",
    "- LSTAT 弱勢群體人口所占比例\n",
    "- MEDV 業主自住房的中位數房價(以千美元計)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data=data.data,columns=data.feature_names)\n",
    "data_df[\"MEDV\"] = data.target\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.describe()\n",
    "# 可以稍微檢查一下 類別型有沒有異常\n",
    "# 百分比率 有沒有不合理\n",
    "# 資料筆數是否相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 檢查有無缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_numeric 將一列或多列轉為數值最佳方法，會嘗試將字串改為整數浮點，若不能轉換則為NAN\n",
    "# astype 強行轉換\n",
    "# infer_objects 推論轉換\n",
    "data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data.target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regplot()：根據資料繪製線性迴歸(Linear Regression)模型圖\n",
    "# 透過簡單線性回歸可看出 平數 與 房價 呈現正相關\n",
    "sns.regplot(x=data_df[\"RM\"], y=data_df[\"MEDV\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#透過皮爾森映射熱力圖看出哪些特徵與目標變數有較高的相關性。\n",
    "\n",
    "sns.set(rc={\"figure.figsize\":(10,5)})\n",
    "sns.heatmap(data=data_df.corr(),cmap=\"RdBu\", #cmap=\"Greens\"\n",
    " annot_kws={\"size\":12},\n",
    " annot=True,\n",
    " fmt=\".2f\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元迴歸分析造成下列的不良影響：\n",
    "1. 膨脹最小平方法（least squares）估計參數值的變異數和共變數，使得迴歸係數的\n",
    "估計值變得很不精確。\n",
    "2. 膨脹迴歸係數估計值的相關係數。\n",
    "3. 膨脹預測值的變異數，但對預測能力不影響。\n",
    "4. 造成解釋迴歸係數及其信賴區間估計之困難。\n",
    "5. 造成整體模式的考驗達顯著，但各別迴歸係數之考驗不顯著的矛盾現象和解釋上\n",
    "之困擾。\n",
    "6. 造成迴歸係數的正負號與所期望者相反的衝突現象，這是由於自變項間之壓抑效\n",
    "果（suppress effect）造成的。\n",
    "一個比較簡單的診斷方法是察看自變項間的相關係數矩陣，看看該矩陣中是否\n",
    "有元素值（即自變項兩兩之間的相關係數值）是大於.90 以上者，若有，即表示該二\n",
    "變項互為「多元共線性變項」，並認為該迴歸分析中有嚴重的多元共線性問題存在。\n",
    "另一個比較正式、客觀的診斷法，則為使用第 j 個自變項的「變異數膨脹因數」\n",
    "（variance inflation factor）作為判斷的指標，凡變異數膨脹因數指標值大於 10 者，\n",
    "即表示第 j 個自變項是一個多元共線性變項。\n",
    "在一般的迴歸分析中，針對這種多元共線性問題，有些統計學家會建議將多元\n",
    "共線性變項予以刪除，不納入迴歸方程式中。但避免多元共線性問題所造成困擾的\n",
    "最佳解決方法，不是刪除該具有多元共線性變項，而是使用所謂的「偏差迴歸分析」\n",
    "（biased regression analysis, BRA）。其中以「山脊型迴歸」（ridge regression）最受到\n",
    "學者們的重視和使用；除此之外，尚有「主成分迴歸」（principal component\n",
    "regression）、「潛在根迴歸」（latent root regression）、「貝氏法迴歸」（Baysean\n",
    "regression）、「遞縮式迴歸」（shrinkage regression）等，不過這些偏差迴歸分析法所獲\n",
    "得的迴歸係數值都是「有偏差的」（biased），亦即這些迴歸係數的期望值不等於母群\n",
    "體的迴歸係數值，所以稱作偏差迴歸係數估計值，而本補救多元共線性問題的方法\n",
    "即稱作偏差迴歸分析法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_df.drop(\"MEDV\",axis=1)\n",
    "y = data_df[\"MEDV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train,y_train)\n",
    "coef_df = pd.DataFrame(columns=x_train.columns,data=reg.coef_.reshape(1,13))\n",
    "predict = pd.DataFrame(reg.predict(x_test))\n",
    "print(\"訓練集score\",reg.score(x_train,y_train))\n",
    "print(\"測試集score\",reg.score(x_test,y_test)) \n",
    "# score 會把x_test拿去predict，之後再與y_test進行r2計算，與統計模型的r2_score一樣\n",
    "# 只是r2_score需要傳入predict的結果\n",
    "print(\"w權重\",reg.coef_)\n",
    "coef_df\n",
    "\n",
    "# 可以看出RM對於房價的影響是比較高的\n",
    "# 負相關的部分可以思考一下為什麼，例如NOX(一氧化碳農度)可以看出對於房價是負影響，可能工業區或嚴重汙染地區"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "如果預測房價和實際房價一致的話，那麼所有的資料點都應該彙\n",
    "集在 y = x 這條線上，但這並不是現實，於是可以看到，除了少數點，大部分點散落在 y = x\n",
    "附近，大趨勢說明預測的結果還不錯。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,predict)\n",
    "plt.ylabel(\"predic price\")\n",
    "plt.xlabel(\"real price\")\n",
    "x = np.arange(0, 50)\n",
    "y = x\n",
    "plt.plot(x, y, color=\"red\", lw=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = pd.Series(predict)\n",
    "#重新設定 index\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "predict.reset_index(inplace=True, drop=True)\n",
    "draw_data = pd.concat([y_test,predict],axis=1)\n",
    "draw_data.columns = [\"實際房價\",\"預測房價\"]\n",
    "#用於正常顯示中文，Apple Mac 可選用 Arial\n",
    "plt.rcParams[\"font.sans-serif\"] = \"Microsoft JhengHei\"\n",
    "#用於正常顯示符號\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "sns.lmplot(x=\"實際房價\", y=\"預測房價\",\n",
    " data=draw_data,\n",
    " height=6,\n",
    " aspect=1.2,\n",
    " ci=95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "量化評估指標\n",
    "###\n",
    "但依經驗歸納如下：R2的\n",
    "值大於 0.75，表示迴歸模型擬合度很好，迴歸方程的可解釋程度較高，即迴歸方程的精度較\n",
    "高。R2 的值在 0.5 和 0.75 之間，表示迴歸模型的擬合可以接受，但需要進一步修正迴歸模型。\n",
    "R2 的值小於 0.5，表示迴歸模型擬合有問題，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "mse = metrics.mean_squared_error(y_test,predict)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, predict))\n",
    "r2 = metrics.r2_score(y_test, predict)\n",
    "print(mse)\n",
    "print(rmse)\n",
    "print(r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練完準確度不高怎麼辦\n",
    "\n",
    "為甚麼「訓練模型的正確率」這麼低呢（正確率：0.7645451026942549）？\n",
    "因為線性迴歸的的方程式為一條直線，當特徵與房價不成線性關係的話，那麼再怎麼分析，正確率都不會高。\n",
    "解決的方法有：(1).只討論呈線性關係的特徵、(2).使用多項式迴歸、(3).降維。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (一) 以特徵重要性訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "boston_house = load_boston()\n",
    "boston_house_df = pd.DataFrame(data=boston_house.data,columns=boston_house.feature_names)\n",
    "boston_house_price = boston_house.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前述分析是直接使用所有的 13 個特徵，如果可以只選取比較重要的特徵出來分析？特別注意到如果要找尋重要性的話，一定要先做標準化，不然數據\n",
    "跑出來的結果會整個失真。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler() # Z-scaler 物件\n",
    "X_scaled = scale.fit_transform(boston_house_df)\n",
    "X_scaled_df = pd.DataFrame(X_scaled,columns=boston_house_df.keys())\n",
    "X_scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "LR_model = LinearRegression()\n",
    "LR_model.fit(X_scaled, boston_house_price)\n",
    "feature_importance = LR_model.coef_ #重要性\n",
    "plt.figure(figsize=(8,6)) #圖形大小\n",
    "plt.bar(X_scaled_df.columns, feature_importance) #繪製成直方圖\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本上數值（取絕對值後）越大代表越重要。因此嘗試將 CRIM、INDUS、CHAS、AGE、\n",
    "B 刪除，只使用 ZN、NOX、RM、DIS、RAD、TAX、PTRATIO、LSTAT 再做一次線性迴歸，\n",
    "來預測房價。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = boston_house_df.drop([\"CRIM\",\"INDUS\",\"CHAS\",\"AGE\",\"B\"],axis=1)\n",
    "y = boston_house_price\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "train_score = model.score(x_train, y_train)\n",
    "print(f\"訓練模型的正確率：{train_score}\")\n",
    "print(f\"測試模型的正確率：{model.score(x_test,y_test)}\")\n",
    "print(\"=\"*45)\n",
    "# #評估模型\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "print(\"1.均方誤差(MSE) =\", mse)\n",
    "print(\"2.均方根誤差(RMSE) =\", rmse)\n",
    "print(\"3.判定係數(R^2）=\", r2)\n",
    "# 以比較重要的特徵下去跑，在這樣的資料下 看起來並沒有比較高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (二) PCA 降維"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition\n",
    "boston_house = load_boston()\n",
    "x = pd.DataFrame(data=boston_house.data,columns=boston_house.feature_names)\n",
    "y = boston_house.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = \\\n",
    " train_test_split(x, y,\n",
    " test_size=0.3,\n",
    " random_state=0) #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standarize our training data\n",
    "std_tool = StandardScaler()\n",
    "std_tool.fit(x_train)\n",
    "x_train = std_tool.transform(x_train)\n",
    "# PC 降維\n",
    "pca = decomposition.PCA(n_components=0.95)\n",
    "pca.fit(x_train)\n",
    "x_train = pca.transform(x_train)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(x_train, y_train) #將資料拿去訓練\n",
    "# Standarize x_test\n",
    "x_test = std_tool.transform(x_test)\n",
    "# Dimension reduction usng PCA\n",
    "x_test = pca.transform(x_test)\n",
    "#將 test 的資料用訓練出來的模型去預測\n",
    "y_predict = lr_model.predict(x_test)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.xlabel(\"Actual price\") #X 軸的標題\n",
    "plt.ylabel(\"Predict pcice\") #Y 軸的標題\n",
    "plt.plot([0,50], [0,50]) #劃一條基準線\n",
    "plt.scatter(y_test, y_predict) #比對預測跟實際的差\n",
    "print(\"train\",lr_model.score(x_train, y_train))\n",
    "print(\"test\",lr_model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (三) 多項式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "boston_house = load_boston()\n",
    "x = pd.DataFrame(data=boston_house.data,columns=boston_house.feature_names)\n",
    "y = boston_house.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.3,random_state=0) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=make_pipeline(PolynomialFeatures(2),LinearRegression())\n",
    "model.fit(x_train,y_train)\n",
    "print(\"train\",model.score(x_train,y_train))\n",
    "print(\"test\",model.score(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM\n",
    "#### 主要優點：\n",
    "1. 解決高維特徵的分類問題和回歸問題很有效,在特徵維度大於樣本數時依然有很好的效\n",
    "果。\n",
    "2. 僅僅使用一部分支援向量來做超平面的決策，無需依賴全部資料。\n",
    "3. 有大量的核函數可以使用，從而可以很靈活的來解決各種非線性的分類回歸問題。\n",
    "4. 樣本量不是海量資料的時候，分類準確率高，泛化能力強。\n",
    "#### 主要缺點：\n",
    "1. 如果特徵維度遠遠大於樣本數，則 SVM 表現一般。\n",
    "2. SVM 在樣本量非常大，核函數映射維度非常高時，計算量過大，不太適合使用。\n",
    "3. 非線性問題的核函數的選"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "boston_house = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = \\\n",
    " train_test_split(boston_house.data, boston_house.target,\n",
    " test_size=0.30,\n",
    " random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.21624037461916024\n",
      "test 0.1811277097860169\n"
     ]
    }
   ],
   "source": [
    "# 無標準化\n",
    "boston_svr = SVR()\n",
    "boston_svr.fit(train_x, train_y)\n",
    "print(\"train\",boston_svr.score(train_x,train_y))\n",
    "print(\"test\",boston_svr.score(test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.6979834985580843\n",
      "test 0.5543454037359111\n"
     ]
    }
   ],
   "source": [
    "# 有標準化\n",
    "ss_x = StandardScaler()\n",
    "train_x = ss_x.fit_transform(train_x)\n",
    "test_x = ss_x.transform(test_x)\n",
    "boston_svr = SVR()\n",
    "boston_svr.fit(train_x, train_y)\n",
    "print(\"train\",boston_svr.score(train_x,train_y))\n",
    "print(\"test\",boston_svr.score(test_x,test_y))\n",
    "boston_svr_test_y_predict = boston_svr.predict(test_x)\n",
    "# len(boston_svr_test_y_predict)\n",
    "# len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 4), dpi=80)\n",
    "plt.plot(range(len(test_y)),\n",
    " test_y,\n",
    " ls=\"-.\",\n",
    " lw=2,\n",
    " c=\"r\",\n",
    " label=\"真實值\")\n",
    "plt.plot(range(len(boston_svr.predict(test_x))),\n",
    " boston_svr.predict(test_x),\n",
    " ls=\"-\",\n",
    " lw=2,\n",
    " c=\"b\",\n",
    " label=\"預測值\")\n",
    "#繪製網格\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"number\") #設置 x 軸的標籤文本\n",
    "plt.ylabel(\"房價\") #設置 y 軸的標籤文本\n",
    "plt.show() #顯示圖形\n",
    "#透過圖形可以直觀的看出，預測值和真實值還是有很大差距的\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns # visualization\n",
    "from sklearn import datasets\n",
    "from sklearn.neural_network import MLPClassifier # neural network\n",
    "from sklearn.neural_network import MLPRegressor # neural network\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_house = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.DataFrame(boston_house.data,columns=boston_house.feature_names)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y= train_test_split(boston_house.data,boston_house.target,test_size=0.3,\n",
    "random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.7715181686187258\n",
      "test 0.6783231888810168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adamw\\OneDrive\\桌面\\VirtualEnv\\v01\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(max_iter=500)\n",
    "mlp.fit(train_x,train_y)\n",
    "print(\"train\",mlp.score(train_x,train_y))\n",
    "print(\"test\",mlp.score(test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.8542463888536667\n",
      "test 0.8422415890219487\n",
      "[28.4 31.1 23.5 26.6 19.6 14.3 50.  14.3 20.7 37.6 20.4 27.5 36.2 32.\n",
      " 33.1 48.8 24.6 26.4 23.2 17.  41.3 14.9 18.5 25.  36.4 19.5 27.1 14.9\n",
      " 46.  17.9 30.3 31.6 23.1 24.7 16.7 18.3  8.4 37.3 22.1 22.  46.7 30.1\n",
      " 12.1 29.1 16.6 23.9 19.9 21.4 45.4 15.6 22.7 12.5 24.3 43.8 22.  33.8\n",
      " 19.3 22.6 16.1 15.  19.6 21.2 50.  50.  29.4 17.8 22.8  8.8 32.5 42.8\n",
      " 12.6 28.6 19.1 50.  27.5 23.7 50.   7.2 18.7 37.  22.9 22.9 17.1 22.\n",
      " 23.6 23.9 27.1 29.  22.2  7.  20.7 18.5 21.6 23.  16.  15.  23.9 24.4\n",
      " 22.6 19.8 22.2 18.6 19.7 23.1 13.5 21.2 23.1 13.6 22.8 18.2 13.1 23.2\n",
      " 22.8 25.1 18.9 10.9 19.3 17.4 15.6 20.6 50.  32.7 21.8 13.4 16.6 23.6\n",
      " 11.  23.8 23.1 33.2 28.2  8.5 32.4 29.6 17.1 24.2 26.4 33.2 10.5  8.8\n",
      " 28.  10.5 15.4 15.3 10.4 15.7 43.1 24.7 21.  19.4 10.9 21.7]\n",
      "[26.51423994 34.73694245 27.2553808  28.71282449 20.51993582 16.21068817\n",
      " 40.6387828  15.22347026 21.52409125 42.06803502 20.40545307 28.07130162\n",
      " 27.5340264  32.20814348 30.47146139 47.91441322 25.16276653 22.90166505\n",
      " 22.5294215  20.63747833 34.88322358 16.34799749 23.04277485 24.11299111\n",
      " 33.28766387 20.89683358 17.29428917 15.56897392 41.01763948 10.44572321\n",
      " 32.57156427 31.08323732 23.91412409 26.45114705 17.74510407 17.05108887\n",
      "  5.16658233 34.5989378  25.24542664 26.74972901 40.17263317 26.39876326\n",
      " 15.25768912 31.84802485 20.35875655 22.90109667 19.29664807 20.42772359\n",
      " 44.23494575 16.42479841 22.5848057  17.07706384 19.02910005 44.25436751\n",
      " 28.54539308 34.68354592 17.30295841 20.07253089 14.46266133 19.04966696\n",
      " 18.85470457 20.4898495  46.59141949 52.48372284 29.85951775 15.88947052\n",
      " 25.00331488 11.27737343 30.5808153  40.42077759 16.8436152  29.21068302\n",
      " 18.52879612 27.13125265 24.90641004 14.79224908 48.29896522  8.33932974\n",
      " 16.01887079 29.63922712 18.41511882 25.53219022 19.98273715 24.88701381\n",
      " 32.43706913 30.91532606 26.50342873 32.16974774 23.1411683   2.55886714\n",
      " 22.89799239 18.19702503 24.92060602 23.06496525 14.92089794 18.08723673\n",
      " 24.74031867 21.65805124 22.96007914 22.40830081 20.94957073 13.29602719\n",
      " 21.59754716 22.69717218 11.34051401 18.86694415 20.49423878 18.1829794\n",
      " 28.33516485 20.09612018  9.60927411 20.48741467 25.56631566 25.6581326\n",
      " 22.2621153  13.53432627 20.55370603 17.87083725 16.06185263 21.51983031\n",
      " 36.26076557 33.60150956 18.45805366 15.44406389 15.75119118 26.4855239\n",
      " 12.38922005 17.78304508 22.45581752 37.78128428 28.72740465  4.23768292\n",
      " 30.92051094 28.73017388 14.40300991 26.78530073 25.40796849 31.38791013\n",
      "  9.64353272  7.12116766 29.05065016  9.73204555 15.15510188 22.68869029\n",
      "  7.30283841 14.99213291 38.66774882 25.84914183 21.34163946 20.28479359\n",
      " 12.02255045 18.16200131]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adamw\\OneDrive\\桌面\\VirtualEnv\\v01\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(train_x)\n",
    "train_x_scaler = scaler.transform(train_x)\n",
    "test_x_scaler = scaler.transform(test_x)\n",
    "mlp = MLPRegressor(max_iter=500)\n",
    "mlp.fit(train_x_scaler,train_y)\n",
    "\n",
    "print(\"train\",mlp.score(train_x_scaler,train_y))\n",
    "print(\"test\",mlp.score(test_x_scaler,test_y))\n",
    "print(test_y)\n",
    "print(mlp.predict(test_x_scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v01",
   "language": "python",
   "name": "v01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dcb8c65f7cc9faaf83071100b0c6a0211c9dce5ac50d6412a04dac4e5a4feb06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
